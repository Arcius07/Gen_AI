# ü§ñ Memory-Enabled Gemini Chatbot

A polite, general-purpose AI chatbot built using **LangChain** and **Google Gemini**, enhanced with **conversation memory** to provide contextual and coherent responses.

---

## üöÄ Features

- Uses **Google Gemini (gemini-2.5-flash)** as the LLM
- Supports multiple memory strategies:
  - Conversation Buffer Memory
  - Sliding Window Memory
  - Conversation Summary Memory
- Maintains conversational context across turns
- Clean and modular Python implementation
- Environment-based API key management

---

## üß† Memory Types Supported

### 1Ô∏è‚É£ Conversation Buffer Memory
Stores the **entire conversation history**.
Best for short conversations where full context is needed.

### 2Ô∏è‚É£ Conversation Window Memory
Keeps only the **last N interactions**.
Efficient for longer chats with limited context requirements.

### 3Ô∏è‚É£ Conversation Summary Memory
Automatically **summarizes older messages** using the LLM.
Useful for long-running conversations.

---

## üõ† Tech Stack

- **Python**
- **LangChain**
- **Google Generative AI (Gemini)**
- **dotenv**

---

## üìÇ Project Structure

---

## üîë Setup Instructions

### 1Ô∏è‚É£ Clone the Repository
```bash
git clone <your-repo-link>
cd memory-gemini-chatbot
```
### 2Ô∏è‚É£ Create Virtual Environment (Optional)
```
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```
### 3Ô∏è‚É£ Install Dependencies
```
pip install langchain langchain-google-genai python-dotenv
```
### 4Ô∏è‚É£ Set Environment Variables
```
Create a .env file:

GOOGLE_API_KEY=your_google_api_key_here
```
### ‚ñ∂Ô∏è Run the Chatbot
```
python chatbot.py

Type exit or quit to stop the chatbot.
```
